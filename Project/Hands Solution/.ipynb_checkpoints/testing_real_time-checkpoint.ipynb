{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating and testing model in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "import os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np \n",
    "\n",
    "#Face Mesh\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "model_path = 'Models/hand_signs_2'\n",
    "data_path = 'Dataset_Processed'\n",
    "tflite_path = 'Models/hand_signs_2.tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility functions\n",
    "\n",
    "def get_Wrist(hand_landmark):\n",
    "    landmark = []\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.WRIST].x)\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.WRIST].y)\n",
    "\n",
    "    return landmark\n",
    "    \n",
    "def get_Thumb_CMC(hand_landmark):\n",
    "    \n",
    "    landmark = []\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.THUMB_CMC].x)\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.THUMB_CMC].y)\n",
    "        \n",
    "    return landmark\n",
    "\n",
    "def get_Thumb_MCP(hand_landmark):\n",
    "    \n",
    "    landmark = []\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.THUMB_MCP].x)\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.THUMB_MCP].y)\n",
    "        \n",
    "    return landmark\n",
    "\n",
    "def get_Thumb_IP(hand_landmark):\n",
    "    \n",
    "    landmark = []\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.THUMB_IP].x)\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.THUMB_IP].y)\n",
    "        \n",
    "    return landmark\n",
    "\n",
    "def get_Thumb_TIP(hand_landmark):\n",
    "    \n",
    "    landmark = []\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.THUMB_TIP].x)\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.THUMB_TIP].y)\n",
    "        \n",
    "    return landmark\n",
    "\n",
    "def get_Index_MCP(hand_landmark):\n",
    "    \n",
    "    landmark = []\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP].x)\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP].y)\n",
    "        \n",
    "    return landmark\n",
    "\n",
    "def get_Index_PIP(hand_landmark):\n",
    "    \n",
    "    landmark = []\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.INDEX_FINGER_PIP].x)\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.INDEX_FINGER_PIP].y)\n",
    "        \n",
    "    return landmark\n",
    "\n",
    "def get_Index_DIP(hand_landmark):\n",
    "    \n",
    "    landmark = []\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.INDEX_FINGER_DIP].x)\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.INDEX_FINGER_DIP].y)\n",
    "        \n",
    "    return landmark\n",
    "\n",
    "def get_Index_TIP(hand_landmark):\n",
    "    \n",
    "    landmark = []\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x)\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y)\n",
    "        \n",
    "    return landmark\n",
    "\n",
    "def get_Middle_MCP(hand_landmark):\n",
    "    \n",
    "    landmark = []\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_MCP].x)\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_MCP].y)\n",
    "        \n",
    "    return landmark\n",
    "\n",
    "def get_Middle_PIP(hand_landmark):\n",
    "    \n",
    "    landmark = []\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_PIP].x)\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_PIP].y)\n",
    "        \n",
    "    return landmark\n",
    "\n",
    "def get_Middle_DIP(hand_landmark):\n",
    "    \n",
    "    landmark = []\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_DIP].x)\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_DIP].y)\n",
    "        \n",
    "    return landmark\n",
    "\n",
    "def get_Middle_TIP(hand_landmark):\n",
    "    \n",
    "    landmark = []\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP].x)\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP].y)\n",
    "        \n",
    "    return landmark\n",
    "\n",
    "def get_Ring_MCP(hand_landmark):\n",
    "    \n",
    "    landmark = []\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.RING_FINGER_MCP].x)\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.RING_FINGER_MCP].y)\n",
    "        \n",
    "    return landmark\n",
    "\n",
    "def get_Ring_PIP(hand_landmark):\n",
    "    \n",
    "    landmark = []\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.RING_FINGER_PIP].x)\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.RING_FINGER_PIP].y)\n",
    "        \n",
    "    return landmark\n",
    "\n",
    "def get_Ring_DIP(hand_landmark):\n",
    "    \n",
    "    landmark = []\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.RING_FINGER_DIP].x)\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.RING_FINGER_DIP].y)\n",
    "        \n",
    "    return landmark\n",
    "\n",
    "def get_Ring_TIP(hand_landmark):\n",
    "    \n",
    "    landmark = []\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.RING_FINGER_TIP].x)\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.RING_FINGER_TIP].y)\n",
    "        \n",
    "    return landmark\n",
    "\n",
    "def get_Pinky_MCP(hand_landmark):\n",
    "    \n",
    "    landmark = []\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.PINKY_MCP].x)\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.PINKY_MCP].y)\n",
    "        \n",
    "    return landmark\n",
    "\n",
    "def get_Pinky_PIP(hand_landmark):\n",
    "    \n",
    "    landmark = []\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.PINKY_PIP].x)\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.PINKY_PIP].y)\n",
    "        \n",
    "    return landmark\n",
    "\n",
    "def get_Pinky_DIP(hand_landmark):\n",
    "    \n",
    "    landmark = []\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.PINKY_DIP].x)\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.PINKY_DIP].y)\n",
    "        \n",
    "    return landmark\n",
    "\n",
    "def get_Pinky_TIP(hand_landmark):\n",
    "    \n",
    "    landmark = []\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.PINKY_TIP].x)\n",
    "    landmark.append(hand_landmark.landmark[mp_hands.HandLandmark.PINKY_TIP].y)\n",
    "        \n",
    "    return landmark\n",
    "\n",
    "\n",
    "def checkHands(results):\n",
    "    handsType = []\n",
    "    for hand_landmark in results.multi_handedness:\n",
    "            handsType.append(hand_landmark.classification[0].label)\n",
    "    return handsType\n",
    "\n",
    "# Getting and arranging hands data by multi_handedness\n",
    "def arrangeHands(all_arr):\n",
    "    if(len(hands_res) == 1):\n",
    "        arranged = replace_Hand(all_arr)\n",
    "    else:\n",
    "        arranged = org_Hand(all_arr)\n",
    "        \n",
    "    return arranged\n",
    "        \n",
    "def replace_Hand(all_arr):\n",
    "    \n",
    "    if((hands_res[0]) == \"Left\"):\n",
    "        left_hand = all_arr\n",
    "        right_hand = np.zeros(21*2)\n",
    "    else:\n",
    "        right_hand = all_arr\n",
    "        left_hand = np.zeros(21*2)\n",
    "        \n",
    "    return np.concatenate([left_hand, right_hand])\n",
    "\n",
    "def org_Hand(all_arr):\n",
    "    \n",
    "    if(hands_res[0] == \"Left\"):\n",
    "        left_hand = all_arr[:42]\n",
    "        right_hand = all_arr[42:]\n",
    "    else:\n",
    "        right_hand = all_arr[:42]\n",
    "        left_hand = all_arr[42:]\n",
    "        \n",
    "    return np.concatenate([left_hand, right_hand])\n",
    "\n",
    "#Collect all landmarks\n",
    "def getHands(results):\n",
    "    all_landmarks = []\n",
    "    for hand_landmark in results.multi_hand_landmarks:\n",
    "        land = get_Wrist(hand_landmark)\n",
    "        all_landmarks.append(land)\n",
    "        land = get_Thumb_CMC(hand_landmark)\n",
    "        all_landmarks.append(land)\n",
    "        land = get_Thumb_MCP(hand_landmark)\n",
    "        all_landmarks.append(land)\n",
    "        land = get_Thumb_IP(hand_landmark)\n",
    "        all_landmarks.append(land)\n",
    "        land = get_Thumb_TIP(hand_landmark)\n",
    "        all_landmarks.append(land)\n",
    "        \n",
    "        land = get_Index_MCP(hand_landmark)\n",
    "        all_landmarks.append(land)\n",
    "        land = get_Index_PIP(hand_landmark)\n",
    "        all_landmarks.append(land)\n",
    "        land = get_Index_DIP(hand_landmark)\n",
    "        all_landmarks.append(land)\n",
    "        land = get_Index_TIP(hand_landmark)\n",
    "        all_landmarks.append(land)\n",
    "        \n",
    "        land = get_Middle_MCP(hand_landmark)\n",
    "        all_landmarks.append(land)\n",
    "        land = get_Middle_PIP(hand_landmark)\n",
    "        all_landmarks.append(land)\n",
    "        land = get_Middle_DIP(hand_landmark)\n",
    "        all_landmarks.append(land)\n",
    "        land = get_Middle_TIP(hand_landmark)\n",
    "        all_landmarks.append(land)\n",
    "        \n",
    "        land = get_Ring_MCP(hand_landmark)\n",
    "        all_landmarks.append(land)\n",
    "        land = get_Ring_PIP(hand_landmark)\n",
    "        all_landmarks.append(land)\n",
    "        land = get_Ring_DIP(hand_landmark)\n",
    "        all_landmarks.append(land)\n",
    "        land = get_Ring_TIP(hand_landmark)\n",
    "        all_landmarks.append(land)\n",
    "        \n",
    "        land = get_Pinky_MCP(hand_landmark)\n",
    "        all_landmarks.append(land)\n",
    "        land = get_Pinky_PIP(hand_landmark)\n",
    "        all_landmarks.append(land)\n",
    "        land = get_Pinky_DIP(hand_landmark)\n",
    "        all_landmarks.append(land)\n",
    "        land = get_Pinky_TIP(hand_landmark)\n",
    "        all_landmarks.append(land)\n",
    "        \n",
    "    #Flattened landmarks\n",
    "    all_arr = np.array(all_landmarks).flatten()\n",
    "    return all_arr    \n",
    "\n",
    "def drawLandmarks():\n",
    "\n",
    "    for hand_landmarks in results.multi_hand_landmarks:\n",
    "\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            hand_landmarks,\n",
    "            mp_hands.HAND_CONNECTIONS,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())\n",
    "        \n",
    "def get_labels(file_name):\n",
    "    with open(file_name) as r: \n",
    "        labels = r.read().splitlines()\n",
    "    return np.array(labels)\n",
    "\n",
    "\n",
    "def data_collection():\n",
    "    if frame_num == 0:\n",
    "\n",
    "        cv2.putText(image, 'STARTING COLLECTION', (200, 200),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 4, cv2.LINE_AA)\n",
    "        cv2.putText(image, 'Collecting frames for {} Video number {}'.format(act, sequence), (15, 12),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "        #Display frames\n",
    "        cv2.imshow(\"MediaPipe Hands\", image)\n",
    "        cv2.waitKey(2000)\n",
    "\n",
    "    else:\n",
    "        cv2.putText(image, 'Collecting frames for {}st video' .format(sequence), (15, 12),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 4, cv2.LINE_AA)\n",
    "\n",
    "        #Display frames\n",
    "        cv2.imshow(\"MediaPipe Hands\", image)\n",
    "        \n",
    "        \n",
    "def draw_Face():\n",
    "    if results2.multi_face_landmarks:\n",
    "        for face_landmarks in results2.multi_face_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=image,\n",
    "                landmark_list=face_landmarks,\n",
    "                connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=mp_drawing_styles\n",
    "                .get_default_face_mesh_tesselation_style())\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=image,\n",
    "                landmark_list=face_landmarks,\n",
    "                connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=mp_drawing_styles\n",
    "                .get_default_face_mesh_contours_style())\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=image,\n",
    "                landmark_list=face_landmarks,\n",
    "                connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=mp_drawing_styles\n",
    "                .get_default_face_mesh_iris_connections_style())\n",
    "            \n",
    "\n",
    "def get_face_landmarks():\n",
    "    face_landmarks = []\n",
    "    for face_mesh in results2.multi_face_landmarks:\n",
    "        for i in range(len(face_mesh.landmark)):\n",
    "            face_landmarks.append(face_mesh.landmark[i].x)\n",
    "            face_landmarks.append(face_mesh.landmark[i].y)\n",
    "    return face_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting labels\n",
    "actions = get_labels(\"labels.txt\")\n",
    "\n",
    "#Thirsty videos worth of data each with 30 frames in length\n",
    "sequence_length = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load keras model\n",
    "model = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Openning webcam\n",
    "sequences = []\n",
    "predicant = []\n",
    "sentence = []\n",
    "threshold = 0.4\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "with mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh:\n",
    "    with mp_hands.Hands(model_complexity=0, min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "        while cap.isOpened():\n",
    "            success, image = cap.read()\n",
    "\n",
    "            if not success:\n",
    "                print('Ignoring empty camera frame!')\n",
    "                continue\n",
    "\n",
    "            # To improve performance, optionally mark the image as not writeable to\n",
    "            # pass by reference.\n",
    "\n",
    "            image = cv2.flip(image, 1)\n",
    "            image.flags.writeable = False\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = hands.process(image)\n",
    "\n",
    "            #For facemesh\n",
    "            results2 = face_mesh.process(image)\n",
    "\n",
    "            # Draw the hand annotations on the image.\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "            if results.multi_hand_landmarks and results2.multi_face_landmarks:\n",
    "\n",
    "                #Checking hand multihandedness\n",
    "                hands_res = checkHands(results)\n",
    "\n",
    "                #Collect all landmarks\n",
    "                all_arr = getHands(results)\n",
    "\n",
    "                #Arrange hands\n",
    "                arranged = arrangeHands(all_arr)\n",
    "\n",
    "                sequences.append(arranged)\n",
    "\n",
    "\n",
    "                if(len(sequences) > 39):\n",
    "                    x = np.expand_dims(sequences, axis = 0)\n",
    "                    res = model.predict(np.expand_dims(sequences, axis = 0))\n",
    "                    print(actions[np.argmax(res)])\n",
    "                    sequences.clear()\n",
    "\n",
    "\n",
    "\n",
    "                    #Vizualization predictions\n",
    "                    if res.flatten()[np.argmax(res)] > threshold:\n",
    "                        if(len(sentence)) > 0:\n",
    "                            if actions[np.argmax(res)] != sentence[-1]:\n",
    "                                sentence.append(actions[np.argmax(res)])\n",
    "                        else:\n",
    "                            sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "                if len(sentence) > 3:\n",
    "                    sentence = sentence[-3:]\n",
    "\n",
    "                cv2.rectangle(image, (0, 0), (640, 40), (245, 117, 16), -1)\n",
    "                cv2.putText(image, ' '.join(sentence), (30, 30),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "                #drawLandmarks()\n",
    "                #draw_Face()\n",
    "\n",
    "                # Show frame display.\n",
    "                cv2.imshow('MediaPipe Hands', image)\n",
    "\n",
    "            else:\n",
    "                #draw_Face()\n",
    "                cv2.imshow('MediaPipe Hands', image)\n",
    "\n",
    "\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "    #Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 40, 84)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempting to convert to tflite\n",
    "\n",
    "# Convert the model\n",
    "#converter = tf.lite.TFLiteConverter.from_saved_model(model_path) # path to the SavedModel directory\n",
    "#tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "#with open(tflite_path, 'wb') as f:   \n",
    "    #f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  [ 1 40 84]\n",
      "Output shape:  [ 1 23]\n"
     ]
    }
   ],
   "source": [
    "#Testing the tflite model\n",
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print('Input shape: ', input_details[0]['shape'])\n",
    "print('Output shape: ', output_details[0]['shape'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Inference time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import timeit\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tflite inference time: 0.009178638458251953 seconds\n",
      "Keras model inference time: 0.5794308185577393 seconds\n"
     ]
    }
   ],
   "source": [
    "# Test model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "#input_data = np.array(np.array(input_shape), dtype=np.float32)\n",
    "input_data = x.astype(np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "start = time.time()\n",
    "interpreter.invoke()\n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "end = time.time()\n",
    "#print(output_data)\n",
    "inf_time = end - start\n",
    "print('Tflite inference time: ' +  str(inf_time) + ' seconds')\n",
    "\n",
    "\n",
    "now = time.time()\n",
    "preds = model.predict(x)\n",
    "then = time.time()\n",
    "\n",
    "h5_time = then - now\n",
    "print('Keras model inference time: ' + str(h5_time) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thankyou'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(output_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_14 (LSTM)               (None, 40, 100)           74000     \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 40, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 150)               150600    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 23)                1173      \n",
      "=================================================================\n",
      "Total params: 256,023\n",
      "Trainable params: 256,023\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating tflite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 84)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data = np.load(data_path + '/X_test.npy')\n",
    "x_data = X_data.astype(np.float32)\n",
    "y_truth = np.load(data_path + '/y_test.npy')\n",
    "len(x_data)\n",
    "x_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for item in x_data:\n",
    "    interpreter.set_tensor(input_details[0]['index'], np.expand_dims(item, axis=0))\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    y_pred.append(np.argmax(output_data))\n",
    "    \n",
    "y_true = []\n",
    "for true in y_truth:\n",
    "    y_true.append(np.argmax(true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.8347826086956521\n",
      "Recall score:  0.8347826086956521\n",
      "Precision score:  0.8347826086956521\n",
      "F1 score:  0.8347826086956521\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy : ', accuracy_score(y_true, y_pred))\n",
    "print(\"Recall score: \", recall_score(y_true, y_pred, average='micro'))\n",
    "print(\"Precision score: \", precision_score(y_true, y_pred, average='micro'))\n",
    "print(\"F1 score: \", f1_score(y_true, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  5,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 16,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  1,  0,  0,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  4,\n",
       "         0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  4,  2,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  3,  0,  0,  0],\n",
       "       [ 0,  0,  0,  2,  0,  0,  0,  5,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  1,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  8,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  3,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  7,  0,  0,  2,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  7,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  4,  1,  0,  0,\n",
       "         0,  0,  0,  1,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  8,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0,  0,  3,  0,  0,  0,  0,  0,  0,  0,  0,  9,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  9,\n",
       "         0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         8,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  6,  2,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0, 12,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  3,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  6,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0, 10,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  1, 12,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0, 12]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.8347826086956521\n",
      "Recall score:  0.8347826086956521\n",
      "Precision score:  0.8347826086956521\n",
      "F1 score:  0.8347826086956521\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X_data)\n",
    "yhat = np.argmax(yhat, axis = 1).tolist()\n",
    "ytrue = np.argmax(y_truth, axis = 1).tolist()\n",
    "\n",
    "print('Accuracy : ', accuracy_score(ytrue, yhat))\n",
    "print(\"Recall score: \", recall_score(ytrue, yhat, average='micro'))\n",
    "print(\"Precision score: \", precision_score(ytrue, yhat, average='micro'))\n",
    "print(\"F1 score: \", f1_score(ytrue, yhat, average='micro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
